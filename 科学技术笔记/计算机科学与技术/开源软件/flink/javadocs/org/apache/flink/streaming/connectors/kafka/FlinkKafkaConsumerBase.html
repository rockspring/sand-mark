<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="zh">
<head>
<!-- Generated by javadoc (1.8.0_144) on Thu May 17 13:42:25 CST 2018 -->
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>FlinkKafkaConsumerBase</title>
<meta name="date" content="2018-05-17">
<link rel="stylesheet" type="text/css" href="../../../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="FlinkKafkaConsumerBase";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":6,"i5":6,"i6":6,"i7":10,"i8":10,"i9":10,"i10":10,"i11":10,"i12":10,"i13":10,"i14":10,"i15":10,"i16":10,"i17":10,"i18":10,"i19":10,"i20":10,"i21":10};
var tabs = {65535:["t0","所有方法"],2:["t2","实例方法"],4:["t3","抽象方法"],8:["t4","具体方法"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>您的浏览器已禁用 JavaScript。</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../../../../index-files/index-1.html">索引</a></li>
<li><a href="../../../../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer09.html" title="org.apache.flink.streaming.connectors.kafka中的类"><span class="typeNameLink">上一个类</span></a></li>
<li><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducer.html" title="org.apache.flink.streaming.connectors.kafka中的类"><span class="typeNameLink">下一个类</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../../index.html?org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" target="_top">框架</a></li>
<li><a href="FlinkKafkaConsumerBase.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li>嵌套&nbsp;|&nbsp;</li>
<li><a href="#field.summary">字段</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li><a href="#field.detail">字段</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.flink.streaming.connectors.kafka</div>
<h2 title="类 FlinkKafkaConsumerBase" class="title">类 FlinkKafkaConsumerBase&lt;T&gt;</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../../../org/apache/flink/api/common/functions/AbstractRichFunction.html" title="org.apache.flink.api.common.functions中的类">org.apache.flink.api.common.functions.AbstractRichFunction</a></li>
<li>
<ul class="inheritance">
<li><a href="../../../../../../org/apache/flink/streaming/api/functions/source/RichParallelSourceFunction.html" title="org.apache.flink.streaming.api.functions.source中的类">org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction</a>&lt;T&gt;</li>
<li>
<ul class="inheritance">
<li>org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase&lt;T&gt;</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt><span class="paramLabel">类型参数:</span></dt>
<dd><code>T</code> - The type of records produced by this data source</dd>
</dl>
<dl>
<dt>所有已实现的接口:</dt>
<dd>java.io.Serializable, <a href="../../../../../../org/apache/flink/api/common/functions/Function.html" title="org.apache.flink.api.common.functions中的接口">Function</a>, <a href="../../../../../../org/apache/flink/api/common/functions/RichFunction.html" title="org.apache.flink.api.common.functions中的接口">RichFunction</a>, <a href="../../../../../../org/apache/flink/api/java/typeutils/ResultTypeQueryable.html" title="org.apache.flink.api.java.typeutils中的接口">ResultTypeQueryable</a>&lt;T&gt;, <a href="../../../../../../org/apache/flink/runtime/state/CheckpointListener.html" title="org.apache.flink.runtime.state中的接口">CheckpointListener</a>, <a href="../../../../../../org/apache/flink/streaming/api/checkpoint/CheckpointedFunction.html" title="org.apache.flink.streaming.api.checkpoint中的接口">CheckpointedFunction</a>, <a href="../../../../../../org/apache/flink/streaming/api/functions/source/ParallelSourceFunction.html" title="org.apache.flink.streaming.api.functions.source中的接口">ParallelSourceFunction</a>&lt;T&gt;, <a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.html" title="org.apache.flink.streaming.api.functions.source中的接口">SourceFunction</a>&lt;T&gt;</dd>
</dl>
<dl>
<dt>直接已知子类:</dt>
<dd><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer08.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumer08</a>, <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer09.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumer09</a></dd>
</dl>
<hr>
<br>
<pre>public abstract class <span class="typeNameLabel">FlinkKafkaConsumerBase&lt;T&gt;</span>
extends <a href="../../../../../../org/apache/flink/streaming/api/functions/source/RichParallelSourceFunction.html" title="org.apache.flink.streaming.api.functions.source中的类">RichParallelSourceFunction</a>&lt;T&gt;
implements <a href="../../../../../../org/apache/flink/runtime/state/CheckpointListener.html" title="org.apache.flink.runtime.state中的接口">CheckpointListener</a>, <a href="../../../../../../org/apache/flink/api/java/typeutils/ResultTypeQueryable.html" title="org.apache.flink.api.java.typeutils中的接口">ResultTypeQueryable</a>&lt;T&gt;, <a href="../../../../../../org/apache/flink/streaming/api/checkpoint/CheckpointedFunction.html" title="org.apache.flink.streaming.api.checkpoint中的接口">CheckpointedFunction</a></pre>
<div class="block">Base class of all Flink Kafka Consumer data sources.
 This implements the common behavior across all Kafka versions.

 <p>The Kafka version specific behavior is defined mainly in the specific subclasses of the
 <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/AbstractFetcher.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类"><code>AbstractFetcher</code></a>.</div>
<dl>
<dt><span class="seeLabel">另请参阅:</span></dt>
<dd><a href="../../../../../../serialized-form.html#org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase">序列化表格</a></dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested.class.summary">
<!--   -->
</a>
<h3>嵌套类概要</h3>
<ul class="blockList">
<li class="blockList"><a name="nested.classes.inherited.from.class.org.apache.flink.streaming.api.functions.source.SourceFunction">
<!--   -->
</a>
<h3>从接口继承的嵌套类/接口&nbsp;org.apache.flink.streaming.api.functions.source.<a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.html" title="org.apache.flink.streaming.api.functions.source中的接口">SourceFunction</a></h3>
<code><a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.SourceContext.html" title="org.apache.flink.streaming.api.functions.source中的接口">SourceFunction.SourceContext</a>&lt;<a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.SourceContext.html" title="SourceFunction.SourceContext中的类型参数">T</a>&gt;</code></li>
</ul>
</li>
</ul>
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.summary">
<!--   -->
</a>
<h3>字段概要</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="字段概要表, 列表字段和解释">
<caption><span>字段</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">限定符和类型</th>
<th class="colLast" scope="col">字段和说明</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../../../org/apache/flink/streaming/util/serialization/KeyedDeserializationSchema.html" title="org.apache.flink.streaming.util.serialization中的接口">KeyedDeserializationSchema</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#deserializer">deserializer</a></span></code>
<div class="block">The schema to convert between Kafka's byte messages, and Flink's objects.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private long</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#discoveryIntervalMillis">discoveryIntervalMillis</a></span></code>
<div class="block">User configured value for discovery interval, in milliseconds.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private java.lang.Thread</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#discoveryLoopThread">discoveryLoopThread</a></span></code>
<div class="block">Discovery loop, executed in a separate thread.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#enableCommitOnCheckpoints">enableCommitOnCheckpoints</a></span></code>
<div class="block">User-set flag determining whether or not to commit on checkpoints.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private <a href="../../../../../../org/apache/flink/metrics/Counter.html" title="org.apache.flink.metrics中的接口">Counter</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#failedCommits">failedCommits</a></span></code>
<div class="block">Counter for failed Kafka offset commits.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/AbstractFetcher.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">AbstractFetcher</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>,?&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#kafkaFetcher">kafkaFetcher</a></span></code>
<div class="block">The fetcher implements the connections to the Kafka brokers.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#KEY_DISABLE_METRICS">KEY_DISABLE_METRICS</a></span></code>
<div class="block">Boolean configuration key to disable metrics tracking.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS">KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS</a></span></code>
<div class="block">Configuration key to define the consumer's partition discovery interval, in milliseconds.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static org.slf4j.Logger</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#LOG">LOG</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#MAX_NUM_PENDING_CHECKPOINTS">MAX_NUM_PENDING_CHECKPOINTS</a></span></code>
<div class="block">The maximum number of pending non-committed checkpoints to track, to avoid memory leaks.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaCommitCallback.html" title="org.apache.flink.streaming.connectors.kafka.internals中的接口">KafkaCommitCallback</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#offsetCommitCallback">offsetCommitCallback</a></span></code>
<div class="block">Callback interface that will be invoked upon async Kafka commit completion.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/config/OffsetCommitMode.html" title="org.apache.flink.streaming.connectors.kafka.config中的枚举">OffsetCommitMode</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#offsetCommitMode">offsetCommitMode</a></span></code>
<div class="block">The offset commit mode for the consumer.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#OFFSETS_STATE_NAME">OFFSETS_STATE_NAME</a></span></code>
<div class="block">State name of the consumer's partition offset states.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#PARTITION_DISCOVERY_DISABLED">PARTITION_DISCOVERY_DISABLED</a></span></code>
<div class="block">The default interval to execute partition discovery,
 in milliseconds (<code>Long.MIN_VALUE</code>, i.e. disabled by default).</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/AbstractPartitionDiscoverer.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">AbstractPartitionDiscoverer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#partitionDiscoverer">partitionDiscoverer</a></span></code>
<div class="block">The partition discoverer, used to find new partitions.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private org.apache.commons.collections.map.LinkedMap</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#pendingOffsetsToCommit">pendingOffsetsToCommit</a></span></code>
<div class="block">Data for pending but uncommitted offsets.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private <a href="../../../../../../org/apache/flink/util/SerializedValue.html" title="org.apache.flink.util中的类">SerializedValue</a>&lt;<a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPeriodicWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口">AssignerWithPeriodicWatermarks</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#periodicWatermarkAssigner">periodicWatermarkAssigner</a></span></code>
<div class="block">Optional timestamp extractor / watermark generator that will be run per Kafka partition,
 to exploit per-partition timestamp characteristics.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private <a href="../../../../../../org/apache/flink/util/SerializedValue.html" title="org.apache.flink.util中的类">SerializedValue</a>&lt;<a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPunctuatedWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口">AssignerWithPunctuatedWatermarks</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#punctuatedWatermarkAssigner">punctuatedWatermarkAssigner</a></span></code>
<div class="block">Optional timestamp extractor / watermark generator that will be run per Kafka partition,
 to exploit per-partition timestamp characteristics.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#restoredFromOldState">restoredFromOldState</a></span></code>
<div class="block">Flag indicating whether the consumer is restored from older state written with Flink 1.1 or 1.2.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private java.util.TreeMap&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#restoredState">restoredState</a></span></code>
<div class="block">The offsets to restore to, if the consumer restores state from a checkpoint.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#running">running</a></span></code>
<div class="block">Flag indicating whether the consumer is still running.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static long</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#serialVersionUID">serialVersionUID</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private java.util.Map&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#specificStartupOffsets">specificStartupOffsets</a></span></code>
<div class="block">Specific startup offsets; only relevant when startup mode is <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/config/StartupMode.html#SPECIFIC_OFFSETS"><code>StartupMode.SPECIFIC_OFFSETS</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/config/StartupMode.html" title="org.apache.flink.streaming.connectors.kafka.config中的枚举">StartupMode</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#startupMode">startupMode</a></span></code>
<div class="block">The startup mode for the consumer (default is <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/config/StartupMode.html#GROUP_OFFSETS"><code>StartupMode.GROUP_OFFSETS</code></a>).</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private java.util.Map&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#subscribedPartitionsToStartOffsets">subscribedPartitionsToStartOffsets</a></span></code>
<div class="block">The set of topic partitions that the source will read, with their initial offsets to start reading from.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private <a href="../../../../../../org/apache/flink/metrics/Counter.html" title="org.apache.flink.metrics中的接口">Counter</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#successfulCommits">successfulCommits</a></span></code>
<div class="block">Counter for successful Kafka offset commits.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicsDescriptor.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicsDescriptor</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#topicsDescriptor">topicsDescriptor</a></span></code>
<div class="block">Describes whether we are discovering partitions for fixed topics or a topic pattern.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private <a href="../../../../../../org/apache/flink/api/common/state/ListState.html" title="org.apache.flink.api.common.state中的接口">ListState</a>&lt;<a href="../../../../../../org/apache/flink/api/java/tuple/Tuple2.html" title="org.apache.flink.api.java.tuple中的类">Tuple2</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#unionOffsetStates">unionOffsetStates</a></span></code>
<div class="block">Accessor for state in the operator state backend.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#useMetrics">useMetrics</a></span></code>
<div class="block">Flag indicating whether or not metrics should be exposed.</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>构造器概要</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="构造器概要表, 列表构造器和解释">
<caption><span>构造器</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">构造器和说明</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#FlinkKafkaConsumerBase-java.util.List-java.util.regex.Pattern-org.apache.flink.streaming.util.serialization.KeyedDeserializationSchema-long-boolean-">FlinkKafkaConsumerBase</a></span>(java.util.List&lt;java.lang.String&gt;&nbsp;topics,
                      java.util.regex.Pattern&nbsp;topicPattern,
                      <a href="../../../../../../org/apache/flink/streaming/util/serialization/KeyedDeserializationSchema.html" title="org.apache.flink.streaming.util.serialization中的接口">KeyedDeserializationSchema</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;deserializer,
                      long&nbsp;discoveryIntervalMillis,
                      boolean&nbsp;useMetrics)</code>
<div class="block">Base constructor.</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>方法概要</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="方法概要表, 列表方法和解释">
<caption><span id="t0" class="activeTableTab"><span>所有方法</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">实例方法</a></span><span class="tabEnd">&nbsp;</span></span><span id="t3" class="tableTab"><span><a href="javascript:show(4);">抽象方法</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">具体方法</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">限定符和类型</th>
<th class="colLast" scope="col">方法和说明</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumerBase</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#assignTimestampsAndWatermarks-org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks-">assignTimestampsAndWatermarks</a></span>(<a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPeriodicWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口">AssignerWithPeriodicWatermarks</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;assigner)</code>
<div class="block">Specifies an <a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPunctuatedWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口"><code>AssignerWithPunctuatedWatermarks</code></a> to emit watermarks in a punctuated manner.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumerBase</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#assignTimestampsAndWatermarks-org.apache.flink.streaming.api.functions.AssignerWithPunctuatedWatermarks-">assignTimestampsAndWatermarks</a></span>(<a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPunctuatedWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口">AssignerWithPunctuatedWatermarks</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;assigner)</code>
<div class="block">Specifies an <a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPunctuatedWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口"><code>AssignerWithPunctuatedWatermarks</code></a> to emit watermarks in a punctuated manner.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#cancel--">cancel</a></span>()</code>
<div class="block">Cancels the source.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#close--">close</a></span>()</code>
<div class="block">Tear-down method for the user code.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>protected abstract <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/AbstractFetcher.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">AbstractFetcher</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>,?&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#createFetcher-org.apache.flink.streaming.api.functions.source.SourceFunction.SourceContext-java.util.Map-org.apache.flink.util.SerializedValue-org.apache.flink.util.SerializedValue-org.apache.flink.streaming.api.operators.StreamingRuntimeContext-org.apache.flink.streaming.connectors.kafka.config.OffsetCommitMode-org.apache.flink.metrics.MetricGroup-boolean-">createFetcher</a></span>(<a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.SourceContext.html" title="org.apache.flink.streaming.api.functions.source中的接口">SourceFunction.SourceContext</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;sourceContext,
             java.util.Map&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt;&nbsp;subscribedPartitionsToStartOffsets,
             <a href="../../../../../../org/apache/flink/util/SerializedValue.html" title="org.apache.flink.util中的类">SerializedValue</a>&lt;<a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPeriodicWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口">AssignerWithPeriodicWatermarks</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&gt;&nbsp;watermarksPeriodic,
             <a href="../../../../../../org/apache/flink/util/SerializedValue.html" title="org.apache.flink.util中的类">SerializedValue</a>&lt;<a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPunctuatedWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口">AssignerWithPunctuatedWatermarks</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&gt;&nbsp;watermarksPunctuated,
             <a href="../../../../../../org/apache/flink/streaming/api/operators/StreamingRuntimeContext.html" title="org.apache.flink.streaming.api.operators中的类">StreamingRuntimeContext</a>&nbsp;runtimeContext,
             <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/config/OffsetCommitMode.html" title="org.apache.flink.streaming.connectors.kafka.config中的枚举">OffsetCommitMode</a>&nbsp;offsetCommitMode,
             <a href="../../../../../../org/apache/flink/metrics/MetricGroup.html" title="org.apache.flink.metrics中的接口">MetricGroup</a>&nbsp;kafkaMetricGroup,
             boolean&nbsp;useMetrics)</code>
<div class="block">Creates the fetcher that connect to the Kafka brokers, pulls data, deserialized the
 data, and emits it into the data streams.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>protected abstract <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/AbstractPartitionDiscoverer.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">AbstractPartitionDiscoverer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#createPartitionDiscoverer-org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicsDescriptor-int-int-">createPartitionDiscoverer</a></span>(<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicsDescriptor.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicsDescriptor</a>&nbsp;topicsDescriptor,
                         int&nbsp;indexOfThisSubtask,
                         int&nbsp;numParallelSubtasks)</code>
<div class="block">Creates the partition discoverer that is used to find new partitions for this subtask.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>protected abstract boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#getIsAutoCommitEnabled--">getIsAutoCommitEnabled</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>(专用程序包) <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/config/OffsetCommitMode.html" title="org.apache.flink.streaming.connectors.kafka.config中的枚举">OffsetCommitMode</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#getOffsetCommitMode--">getOffsetCommitMode</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>(专用程序包) org.apache.commons.collections.map.LinkedMap</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#getPendingOffsetsToCommit--">getPendingOffsetsToCommit</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code><a href="../../../../../../org/apache/flink/api/common/typeinfo/TypeInformation.html" title="org.apache.flink.api.common.typeinfo中的类">TypeInformation</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#getProducedType--">getProducedType</a></span>()</code>
<div class="block">Gets the data type (as a <a href="../../../../../../org/apache/flink/api/common/typeinfo/TypeInformation.html" title="org.apache.flink.api.common.typeinfo中的类"><code>TypeInformation</code></a>) produced by this function or input format.</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>(专用程序包) java.util.TreeMap&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#getRestoredState--">getRestoredState</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code>(专用程序包) java.util.Map&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#getSubscribedPartitionsToStartOffsets--">getSubscribedPartitionsToStartOffsets</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#initializeState-org.apache.flink.runtime.state.FunctionInitializationContext-">initializeState</a></span>(<a href="../../../../../../org/apache/flink/runtime/state/FunctionInitializationContext.html" title="org.apache.flink.runtime.state中的接口">FunctionInitializationContext</a>&nbsp;context)</code>
<div class="block">This method is called when the parallel function instance is created during distributed
 execution.</div>
</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#notifyCheckpointComplete-long-">notifyCheckpointComplete</a></span>(long&nbsp;checkpointId)</code>
<div class="block">This method is called as a notification once a distributed checkpoint has been completed.</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#open-org.apache.flink.configuration.Configuration-">open</a></span>(<a href="../../../../../../org/apache/flink/configuration/Configuration.html" title="org.apache.flink.configuration中的类">Configuration</a>&nbsp;configuration)</code>
<div class="block">Initialization method for the function.</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#run-org.apache.flink.streaming.api.functions.source.SourceFunction.SourceContext-">run</a></span>(<a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.SourceContext.html" title="org.apache.flink.streaming.api.functions.source中的接口">SourceFunction.SourceContext</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;sourceContext)</code>
<div class="block">Starts the source.</div>
</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumerBase</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#setCommitOffsetsOnCheckpoints-boolean-">setCommitOffsetsOnCheckpoints</a></span>(boolean&nbsp;commitOnCheckpoints)</code>
<div class="block">Specifies whether or not the consumer should commit offsets back to Kafka on checkpoints.</div>
</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumerBase</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#setStartFromEarliest--">setStartFromEarliest</a></span>()</code>
<div class="block">Specifies the consumer to start reading from the earliest offset for all partitions.</div>
</td>
</tr>
<tr id="i18" class="altColor">
<td class="colFirst"><code><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumerBase</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#setStartFromGroupOffsets--">setStartFromGroupOffsets</a></span>()</code>
<div class="block">Specifies the consumer to start reading from any committed group offsets found
 in Zookeeper / Kafka brokers.</div>
</td>
</tr>
<tr id="i19" class="rowColor">
<td class="colFirst"><code><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumerBase</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#setStartFromLatest--">setStartFromLatest</a></span>()</code>
<div class="block">Specifies the consumer to start reading from the latest offset for all partitions.</div>
</td>
</tr>
<tr id="i20" class="altColor">
<td class="colFirst"><code><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumerBase</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#setStartFromSpecificOffsets-java.util.Map-">setStartFromSpecificOffsets</a></span>(java.util.Map&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt;&nbsp;specificStartupOffsets)</code>
<div class="block">Specifies the consumer to start reading partitions from specific offsets, set independently for each partition.</div>
</td>
</tr>
<tr id="i21" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#snapshotState-org.apache.flink.runtime.state.FunctionSnapshotContext-">snapshotState</a></span>(<a href="../../../../../../org/apache/flink/runtime/state/FunctionSnapshotContext.html" title="org.apache.flink.runtime.state中的接口">FunctionSnapshotContext</a>&nbsp;context)</code>
<div class="block">This method is called when a snapshot for a checkpoint is requested.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.org.apache.flink.api.common.functions.AbstractRichFunction">
<!--   -->
</a>
<h3>从类继承的方法&nbsp;org.apache.flink.api.common.functions.<a href="../../../../../../org/apache/flink/api/common/functions/AbstractRichFunction.html" title="org.apache.flink.api.common.functions中的类">AbstractRichFunction</a></h3>
<code><a href="../../../../../../org/apache/flink/api/common/functions/AbstractRichFunction.html#getIterationRuntimeContext--">getIterationRuntimeContext</a>, <a href="../../../../../../org/apache/flink/api/common/functions/AbstractRichFunction.html#getRuntimeContext--">getRuntimeContext</a>, <a href="../../../../../../org/apache/flink/api/common/functions/AbstractRichFunction.html#setRuntimeContext-org.apache.flink.api.common.functions.RuntimeContext-">setRuntimeContext</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.java.lang.Object">
<!--   -->
</a>
<h3>从类继承的方法&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.detail">
<!--   -->
</a>
<h3>字段详细资料</h3>
<a name="serialVersionUID">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>serialVersionUID</h4>
<pre>private static final&nbsp;long serialVersionUID</pre>
<dl>
<dt><span class="seeLabel">另请参阅:</span></dt>
<dd><a href="../../../../../../constant-values.html#org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.serialVersionUID">常量字段值</a></dd>
</dl>
</li>
</ul>
<a name="LOG">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>LOG</h4>
<pre>protected static final&nbsp;org.slf4j.Logger LOG</pre>
</li>
</ul>
<a name="MAX_NUM_PENDING_CHECKPOINTS">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>MAX_NUM_PENDING_CHECKPOINTS</h4>
<pre>public static final&nbsp;int MAX_NUM_PENDING_CHECKPOINTS</pre>
<div class="block">The maximum number of pending non-committed checkpoints to track, to avoid memory leaks.</div>
<dl>
<dt><span class="seeLabel">另请参阅:</span></dt>
<dd><a href="../../../../../../constant-values.html#org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.MAX_NUM_PENDING_CHECKPOINTS">常量字段值</a></dd>
</dl>
</li>
</ul>
<a name="PARTITION_DISCOVERY_DISABLED">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>PARTITION_DISCOVERY_DISABLED</h4>
<pre>public static final&nbsp;long PARTITION_DISCOVERY_DISABLED</pre>
<div class="block">The default interval to execute partition discovery,
 in milliseconds (<code>Long.MIN_VALUE</code>, i.e. disabled by default).</div>
<dl>
<dt><span class="seeLabel">另请参阅:</span></dt>
<dd><a href="../../../../../../constant-values.html#org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.PARTITION_DISCOVERY_DISABLED">常量字段值</a></dd>
</dl>
</li>
</ul>
<a name="KEY_DISABLE_METRICS">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>KEY_DISABLE_METRICS</h4>
<pre>public static final&nbsp;java.lang.String KEY_DISABLE_METRICS</pre>
<div class="block">Boolean configuration key to disable metrics tracking.</div>
<dl>
<dt><span class="seeLabel">另请参阅:</span></dt>
<dd><a href="../../../../../../constant-values.html#org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.KEY_DISABLE_METRICS">常量字段值</a></dd>
</dl>
</li>
</ul>
<a name="KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS</h4>
<pre>public static final&nbsp;java.lang.String KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS</pre>
<div class="block">Configuration key to define the consumer's partition discovery interval, in milliseconds.</div>
<dl>
<dt><span class="seeLabel">另请参阅:</span></dt>
<dd><a href="../../../../../../constant-values.html#org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS">常量字段值</a></dd>
</dl>
</li>
</ul>
<a name="OFFSETS_STATE_NAME">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>OFFSETS_STATE_NAME</h4>
<pre>private static final&nbsp;java.lang.String OFFSETS_STATE_NAME</pre>
<div class="block">State name of the consumer's partition offset states.</div>
<dl>
<dt><span class="seeLabel">另请参阅:</span></dt>
<dd><a href="../../../../../../constant-values.html#org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.OFFSETS_STATE_NAME">常量字段值</a></dd>
</dl>
</li>
</ul>
<a name="topicsDescriptor">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>topicsDescriptor</h4>
<pre>private final&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicsDescriptor.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicsDescriptor</a> topicsDescriptor</pre>
<div class="block">Describes whether we are discovering partitions for fixed topics or a topic pattern.</div>
</li>
</ul>
<a name="deserializer">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>deserializer</h4>
<pre>protected final&nbsp;<a href="../../../../../../org/apache/flink/streaming/util/serialization/KeyedDeserializationSchema.html" title="org.apache.flink.streaming.util.serialization中的接口">KeyedDeserializationSchema</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt; deserializer</pre>
<div class="block">The schema to convert between Kafka's byte messages, and Flink's objects.</div>
</li>
</ul>
<a name="subscribedPartitionsToStartOffsets">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subscribedPartitionsToStartOffsets</h4>
<pre>private&nbsp;java.util.Map&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt; subscribedPartitionsToStartOffsets</pre>
<div class="block">The set of topic partitions that the source will read, with their initial offsets to start reading from.</div>
</li>
</ul>
<a name="periodicWatermarkAssigner">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>periodicWatermarkAssigner</h4>
<pre>private&nbsp;<a href="../../../../../../org/apache/flink/util/SerializedValue.html" title="org.apache.flink.util中的类">SerializedValue</a>&lt;<a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPeriodicWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口">AssignerWithPeriodicWatermarks</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&gt; periodicWatermarkAssigner</pre>
<div class="block">Optional timestamp extractor / watermark generator that will be run per Kafka partition,
 to exploit per-partition timestamp characteristics.
 The assigner is kept in serialized form, to deserialize it into multiple copies.</div>
</li>
</ul>
<a name="punctuatedWatermarkAssigner">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>punctuatedWatermarkAssigner</h4>
<pre>private&nbsp;<a href="../../../../../../org/apache/flink/util/SerializedValue.html" title="org.apache.flink.util中的类">SerializedValue</a>&lt;<a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPunctuatedWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口">AssignerWithPunctuatedWatermarks</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&gt; punctuatedWatermarkAssigner</pre>
<div class="block">Optional timestamp extractor / watermark generator that will be run per Kafka partition,
 to exploit per-partition timestamp characteristics.
 The assigner is kept in serialized form, to deserialize it into multiple copies.</div>
</li>
</ul>
<a name="enableCommitOnCheckpoints">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>enableCommitOnCheckpoints</h4>
<pre>private&nbsp;boolean enableCommitOnCheckpoints</pre>
<div class="block">User-set flag determining whether or not to commit on checkpoints.
 Note: this flag does not represent the final offset commit mode.</div>
</li>
</ul>
<a name="offsetCommitMode">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>offsetCommitMode</h4>
<pre>private&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/config/OffsetCommitMode.html" title="org.apache.flink.streaming.connectors.kafka.config中的枚举">OffsetCommitMode</a> offsetCommitMode</pre>
<div class="block">The offset commit mode for the consumer.
 The value of this can only be determined in <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#open-org.apache.flink.configuration.Configuration-"><code>open(Configuration)</code></a> since it depends
 on whether or not checkpointing is enabled for the job.</div>
</li>
</ul>
<a name="discoveryIntervalMillis">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>discoveryIntervalMillis</h4>
<pre>private final&nbsp;long discoveryIntervalMillis</pre>
<div class="block">User configured value for discovery interval, in milliseconds.</div>
</li>
</ul>
<a name="startupMode">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>startupMode</h4>
<pre>private&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/config/StartupMode.html" title="org.apache.flink.streaming.connectors.kafka.config中的枚举">StartupMode</a> startupMode</pre>
<div class="block">The startup mode for the consumer (default is <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/config/StartupMode.html#GROUP_OFFSETS"><code>StartupMode.GROUP_OFFSETS</code></a>).</div>
</li>
</ul>
<a name="specificStartupOffsets">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>specificStartupOffsets</h4>
<pre>private&nbsp;java.util.Map&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt; specificStartupOffsets</pre>
<div class="block">Specific startup offsets; only relevant when startup mode is <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/config/StartupMode.html#SPECIFIC_OFFSETS"><code>StartupMode.SPECIFIC_OFFSETS</code></a>.</div>
</li>
</ul>
<a name="pendingOffsetsToCommit">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pendingOffsetsToCommit</h4>
<pre>private final&nbsp;org.apache.commons.collections.map.LinkedMap pendingOffsetsToCommit</pre>
<div class="block">Data for pending but uncommitted offsets.</div>
</li>
</ul>
<a name="kafkaFetcher">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>kafkaFetcher</h4>
<pre>private transient volatile&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/AbstractFetcher.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">AbstractFetcher</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>,?&gt; kafkaFetcher</pre>
<div class="block">The fetcher implements the connections to the Kafka brokers.</div>
</li>
</ul>
<a name="partitionDiscoverer">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitionDiscoverer</h4>
<pre>private transient volatile&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/AbstractPartitionDiscoverer.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">AbstractPartitionDiscoverer</a> partitionDiscoverer</pre>
<div class="block">The partition discoverer, used to find new partitions.</div>
</li>
</ul>
<a name="restoredState">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>restoredState</h4>
<pre>private transient volatile&nbsp;java.util.TreeMap&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt; restoredState</pre>
<div class="block">The offsets to restore to, if the consumer restores state from a checkpoint.

 <p>This map will be populated by the <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#initializeState-org.apache.flink.runtime.state.FunctionInitializationContext-"><code>initializeState(FunctionInitializationContext)</code></a> method.

 <p>Using a sorted map as the ordering is important when using restored state
 to seed the partition discoverer.</div>
</li>
</ul>
<a name="unionOffsetStates">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>unionOffsetStates</h4>
<pre>private transient&nbsp;<a href="../../../../../../org/apache/flink/api/common/state/ListState.html" title="org.apache.flink.api.common.state中的接口">ListState</a>&lt;<a href="../../../../../../org/apache/flink/api/java/tuple/Tuple2.html" title="org.apache.flink.api.java.tuple中的类">Tuple2</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt;&gt; unionOffsetStates</pre>
<div class="block">Accessor for state in the operator state backend.</div>
</li>
</ul>
<a name="restoredFromOldState">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>restoredFromOldState</h4>
<pre>private&nbsp;boolean restoredFromOldState</pre>
<div class="block">Flag indicating whether the consumer is restored from older state written with Flink 1.1 or 1.2.
 When the current run is restored from older state, partition discovery is disabled.</div>
</li>
</ul>
<a name="discoveryLoopThread">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>discoveryLoopThread</h4>
<pre>private transient volatile&nbsp;java.lang.Thread discoveryLoopThread</pre>
<div class="block">Discovery loop, executed in a separate thread.</div>
</li>
</ul>
<a name="running">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>running</h4>
<pre>private volatile&nbsp;boolean running</pre>
<div class="block">Flag indicating whether the consumer is still running.</div>
</li>
</ul>
<a name="useMetrics">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>useMetrics</h4>
<pre>private final&nbsp;boolean useMetrics</pre>
<div class="block">Flag indicating whether or not metrics should be exposed.
 If <code>true</code>, offset metrics (e.g. current offset, committed offset) and
 Kafka-shipped metrics will be registered.</div>
</li>
</ul>
<a name="successfulCommits">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>successfulCommits</h4>
<pre>private transient&nbsp;<a href="../../../../../../org/apache/flink/metrics/Counter.html" title="org.apache.flink.metrics中的接口">Counter</a> successfulCommits</pre>
<div class="block">Counter for successful Kafka offset commits.</div>
</li>
</ul>
<a name="failedCommits">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>failedCommits</h4>
<pre>private transient&nbsp;<a href="../../../../../../org/apache/flink/metrics/Counter.html" title="org.apache.flink.metrics中的接口">Counter</a> failedCommits</pre>
<div class="block">Counter for failed Kafka offset commits.</div>
</li>
</ul>
<a name="offsetCommitCallback">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>offsetCommitCallback</h4>
<pre>private transient&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaCommitCallback.html" title="org.apache.flink.streaming.connectors.kafka.internals中的接口">KafkaCommitCallback</a> offsetCommitCallback</pre>
<div class="block">Callback interface that will be invoked upon async Kafka commit completion.
  Please be aware that default callback implementation in base class does not
  provide any guarantees on thread-safety. This is sufficient for now because current
  supported Kafka connectors guarantee no more than 1 concurrent async pending offset
  commit.</div>
</li>
</ul>
</li>
</ul>
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>构造器详细资料</h3>
<a name="FlinkKafkaConsumerBase-java.util.List-java.util.regex.Pattern-org.apache.flink.streaming.util.serialization.KeyedDeserializationSchema-long-boolean-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>FlinkKafkaConsumerBase</h4>
<pre>public&nbsp;FlinkKafkaConsumerBase(java.util.List&lt;java.lang.String&gt;&nbsp;topics,
                              java.util.regex.Pattern&nbsp;topicPattern,
                              <a href="../../../../../../org/apache/flink/streaming/util/serialization/KeyedDeserializationSchema.html" title="org.apache.flink.streaming.util.serialization中的接口">KeyedDeserializationSchema</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;deserializer,
                              long&nbsp;discoveryIntervalMillis,
                              boolean&nbsp;useMetrics)</pre>
<div class="block">Base constructor.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>topics</code> - fixed list of topics to subscribe to (null, if using topic pattern)</dd>
<dd><code>topicPattern</code> - the topic pattern to subscribe to (null, if using fixed topics)</dd>
<dd><code>deserializer</code> - The deserializer to turn raw byte messages into Java/Scala objects.</dd>
<dd><code>discoveryIntervalMillis</code> - the topic / partition discovery interval, in
                                milliseconds (0 if discovery is disabled).</dd>
</dl>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>方法详细资料</h3>
<a name="assignTimestampsAndWatermarks-org.apache.flink.streaming.api.functions.AssignerWithPunctuatedWatermarks-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>assignTimestampsAndWatermarks</h4>
<pre>public&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumerBase</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;assignTimestampsAndWatermarks(<a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPunctuatedWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口">AssignerWithPunctuatedWatermarks</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;assigner)</pre>
<div class="block">Specifies an <a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPunctuatedWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口"><code>AssignerWithPunctuatedWatermarks</code></a> to emit watermarks in a punctuated manner.
 The watermark extractor will run per Kafka partition, watermarks will be merged across partitions
 in the same way as in the Flink runtime, when streams are merged.

 <p>When a subtask of a FlinkKafkaConsumer source reads multiple Kafka partitions,
 the streams from the partitions are unioned in a "first come first serve" fashion. Per-partition
 characteristics are usually lost that way. For example, if the timestamps are strictly ascending
 per Kafka partition, they will not be strictly ascending in the resulting Flink DataStream, if the
 parallel source subtask reads more that one partition.

 <p>Running timestamp extractors / watermark generators directly inside the Kafka source, per Kafka
 partition, allows users to let them exploit the per-partition characteristics.

 <p>Note: One can use either an <a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPunctuatedWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口"><code>AssignerWithPunctuatedWatermarks</code></a> or an
 <a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPeriodicWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口"><code>AssignerWithPeriodicWatermarks</code></a>, not both at the same time.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>assigner</code> - The timestamp assigner / watermark generator to use.</dd>
<dt><span class="returnLabel">返回:</span></dt>
<dd>The consumer object, to allow function chaining.</dd>
</dl>
</li>
</ul>
<a name="assignTimestampsAndWatermarks-org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>assignTimestampsAndWatermarks</h4>
<pre>public&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumerBase</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;assignTimestampsAndWatermarks(<a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPeriodicWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口">AssignerWithPeriodicWatermarks</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;assigner)</pre>
<div class="block">Specifies an <a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPunctuatedWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口"><code>AssignerWithPunctuatedWatermarks</code></a> to emit watermarks in a punctuated manner.
 The watermark extractor will run per Kafka partition, watermarks will be merged across partitions
 in the same way as in the Flink runtime, when streams are merged.

 <p>When a subtask of a FlinkKafkaConsumer source reads multiple Kafka partitions,
 the streams from the partitions are unioned in a "first come first serve" fashion. Per-partition
 characteristics are usually lost that way. For example, if the timestamps are strictly ascending
 per Kafka partition, they will not be strictly ascending in the resulting Flink DataStream, if the
 parallel source subtask reads more that one partition.

 <p>Running timestamp extractors / watermark generators directly inside the Kafka source, per Kafka
 partition, allows users to let them exploit the per-partition characteristics.

 <p>Note: One can use either an <a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPunctuatedWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口"><code>AssignerWithPunctuatedWatermarks</code></a> or an
 <a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPeriodicWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口"><code>AssignerWithPeriodicWatermarks</code></a>, not both at the same time.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>assigner</code> - The timestamp assigner / watermark generator to use.</dd>
<dt><span class="returnLabel">返回:</span></dt>
<dd>The consumer object, to allow function chaining.</dd>
</dl>
</li>
</ul>
<a name="setCommitOffsetsOnCheckpoints-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setCommitOffsetsOnCheckpoints</h4>
<pre>public&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumerBase</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;setCommitOffsetsOnCheckpoints(boolean&nbsp;commitOnCheckpoints)</pre>
<div class="block">Specifies whether or not the consumer should commit offsets back to Kafka on checkpoints.

 <p>This setting will only have effect if checkpointing is enabled for the job.
 If checkpointing isn't enabled, only the "auto.commit.enable" (for 0.8) / "enable.auto.commit" (for 0.9+)
 property settings will be</div>
<dl>
<dt><span class="returnLabel">返回:</span></dt>
<dd>The consumer object, to allow function chaining.</dd>
</dl>
</li>
</ul>
<a name="setStartFromEarliest--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setStartFromEarliest</h4>
<pre>public&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumerBase</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;setStartFromEarliest()</pre>
<div class="block">Specifies the consumer to start reading from the earliest offset for all partitions.
 This lets the consumer ignore any committed group offsets in Zookeeper / Kafka brokers.

 <p>This method does not effect where partitions are read from when the consumer is restored
 from a checkpoint or savepoint. When the consumer is restored from a checkpoint or
 savepoint, only the offsets in the restored state will be used.</div>
<dl>
<dt><span class="returnLabel">返回:</span></dt>
<dd>The consumer object, to allow function chaining.</dd>
</dl>
</li>
</ul>
<a name="setStartFromLatest--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setStartFromLatest</h4>
<pre>public&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumerBase</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;setStartFromLatest()</pre>
<div class="block">Specifies the consumer to start reading from the latest offset for all partitions.
 This lets the consumer ignore any committed group offsets in Zookeeper / Kafka brokers.

 <p>This method does not effect where partitions are read from when the consumer is restored
 from a checkpoint or savepoint. When the consumer is restored from a checkpoint or
 savepoint, only the offsets in the restored state will be used.</div>
<dl>
<dt><span class="returnLabel">返回:</span></dt>
<dd>The consumer object, to allow function chaining.</dd>
</dl>
</li>
</ul>
<a name="setStartFromGroupOffsets--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setStartFromGroupOffsets</h4>
<pre>public&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumerBase</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;setStartFromGroupOffsets()</pre>
<div class="block">Specifies the consumer to start reading from any committed group offsets found
 in Zookeeper / Kafka brokers. The "group.id" property must be set in the configuration
 properties. If no offset can be found for a partition, the behaviour in "auto.offset.reset"
 set in the configuration properties will be used for the partition.

 <p>This method does not effect where partitions are read from when the consumer is restored
 from a checkpoint or savepoint. When the consumer is restored from a checkpoint or
 savepoint, only the offsets in the restored state will be used.</div>
<dl>
<dt><span class="returnLabel">返回:</span></dt>
<dd>The consumer object, to allow function chaining.</dd>
</dl>
</li>
</ul>
<a name="setStartFromSpecificOffsets-java.util.Map-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setStartFromSpecificOffsets</h4>
<pre>public&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="org.apache.flink.streaming.connectors.kafka中的类">FlinkKafkaConsumerBase</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;setStartFromSpecificOffsets(java.util.Map&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt;&nbsp;specificStartupOffsets)</pre>
<div class="block">Specifies the consumer to start reading partitions from specific offsets, set independently for each partition.
 The specified offset should be the offset of the next record that will be read from partitions.
 This lets the consumer ignore any committed group offsets in Zookeeper / Kafka brokers.

 <p>If the provided map of offsets contains entries whose <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类"><code>KafkaTopicPartition</code></a> is not subscribed by the
 consumer, the entry will be ignored. If the consumer subscribes to a partition that does not exist in the provided
 map of offsets, the consumer will fallback to the default group offset behaviour (see
 <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html#setStartFromGroupOffsets--"><code>setStartFromGroupOffsets()</code></a>) for that particular partition.

 <p>If the specified offset for a partition is invalid, or the behaviour for that partition is defaulted to group
 offsets but still no group offset could be found for it, then the "auto.offset.reset" behaviour set in the
 configuration properties will be used for the partition

 <p>This method does not effect where partitions are read from when the consumer is restored
 from a checkpoint or savepoint. When the consumer is restored from a checkpoint or
 savepoint, only the offsets in the restored state will be used.</div>
<dl>
<dt><span class="returnLabel">返回:</span></dt>
<dd>The consumer object, to allow function chaining.</dd>
</dl>
</li>
</ul>
<a name="open-org.apache.flink.configuration.Configuration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>open</h4>
<pre>public&nbsp;void&nbsp;open(<a href="../../../../../../org/apache/flink/configuration/Configuration.html" title="org.apache.flink.configuration中的类">Configuration</a>&nbsp;configuration)
          throws java.lang.Exception</pre>
<div class="block"><span class="descfrmTypeLabel">从接口复制的说明:&nbsp;<code><a href="../../../../../../org/apache/flink/api/common/functions/RichFunction.html#open-org.apache.flink.configuration.Configuration-">RichFunction</a></code></span></div>
<div class="block">Initialization method for the function. It is called before the actual working methods 
 (like <i>map</i> or <i>join</i>) and thus suitable for one time setup work. For functions that
 are part of an iteration, this method will be invoked at the beginning of each iteration superstep.
 <p>
 The configuration object passed to the function can be used for configuration and initialization.
 The configuration contains all parameters that were configured on the function in the program
 composition.
 
 <pre><code>
 public class MyMapper extends FilterFunction&lt;String&gt; {
 
     private String searchString;
     
     public void open(Configuration parameters) {
         this.searchString = parameters.getString("foo");
     }
     
     public boolean filter(String value) {
         return value.equals(searchString);
     }
 }
 </code></pre>
 <p>
 By default, this method does nothing.</div>
<dl>
<dt><span class="overrideSpecifyLabel">指定者:</span></dt>
<dd><code><a href="../../../../../../org/apache/flink/api/common/functions/RichFunction.html#open-org.apache.flink.configuration.Configuration-">open</a></code>&nbsp;在接口中&nbsp;<code><a href="../../../../../../org/apache/flink/api/common/functions/RichFunction.html" title="org.apache.flink.api.common.functions中的接口">RichFunction</a></code></dd>
<dt><span class="overrideSpecifyLabel">覆盖:</span></dt>
<dd><code><a href="../../../../../../org/apache/flink/api/common/functions/AbstractRichFunction.html#open-org.apache.flink.configuration.Configuration-">open</a></code>&nbsp;在类中&nbsp;<code><a href="../../../../../../org/apache/flink/api/common/functions/AbstractRichFunction.html" title="org.apache.flink.api.common.functions中的类">AbstractRichFunction</a></code></dd>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>configuration</code> - The configuration containing the parameters attached to the contract.</dd>
<dt><span class="throwsLabel">抛出:</span></dt>
<dd><code>java.lang.Exception</code> - Implementations may forward exceptions, which are caught by the runtime. When the
                   runtime catches an exception, it aborts the task and lets the fail-over logic
                   decide whether to retry the task execution.</dd>
<dt><span class="seeLabel">另请参阅:</span></dt>
<dd><a href="../../../../../../org/apache/flink/configuration/Configuration.html" title="org.apache.flink.configuration中的类"><code>Configuration</code></a></dd>
</dl>
</li>
</ul>
<a name="run-org.apache.flink.streaming.api.functions.source.SourceFunction.SourceContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>run</h4>
<pre>public&nbsp;void&nbsp;run(<a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.SourceContext.html" title="org.apache.flink.streaming.api.functions.source中的接口">SourceFunction.SourceContext</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;sourceContext)
         throws java.lang.Exception</pre>
<div class="block"><span class="descfrmTypeLabel">从接口复制的说明:&nbsp;<code><a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.html#run-org.apache.flink.streaming.api.functions.source.SourceFunction.SourceContext-">SourceFunction</a></code></span></div>
<div class="block">Starts the source. Implementations can use the <a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.SourceContext.html" title="org.apache.flink.streaming.api.functions.source中的接口"><code>SourceFunction.SourceContext</code></a> emit
 elements.

 <p>Sources that implement <a href="../../../../../../org/apache/flink/streaming/api/checkpoint/CheckpointedFunction.html" title="org.apache.flink.streaming.api.checkpoint中的接口"><code>CheckpointedFunction</code></a>
 must lock on the checkpoint lock (using a synchronized block) before updating internal
 state and emitting elements, to make both an atomic operation:

 <pre><code>
  public class ExampleCountSource implements SourceFunction&lt;Long&gt;, CheckpointedFunction {
      private long count = 0L;
      private volatile boolean isRunning = true;

      private transient ListState&lt;Long&gt; checkpointedCount;

      public void run(SourceContext&lt;T&gt; ctx) {
          while (isRunning &amp;&amp; count &lt; 1000) {
              // this synchronized block ensures that state checkpointing,
              // internal state updates and emission of elements are an atomic operation
              synchronized (ctx.getCheckpointLock()) {
                  ctx.collect(count);
                  count++;
              }
          }
      }

      public void cancel() {
          isRunning = false;
      }

      public void initializeState(FunctionInitializationContext context) {
          this.checkpointedCount = context
              .getOperatorStateStore()
              .getListState(new ListStateDescriptor&lt;&gt;("count", Long.class));

          if (context.isRestored()) {
              for (Long count : this.checkpointedCount.get()) {
                  this.count = count;
              }
          }
      }

      public void snapshotState(FunctionSnapshotContext context) {
          this.checkpointedCount.clear();
          this.checkpointedCount.add(count);
      }
 }
 </code></pre></div>
<dl>
<dt><span class="overrideSpecifyLabel">指定者:</span></dt>
<dd><code><a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.html#run-org.apache.flink.streaming.api.functions.source.SourceFunction.SourceContext-">run</a></code>&nbsp;在接口中&nbsp;<code><a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.html" title="org.apache.flink.streaming.api.functions.source中的接口">SourceFunction</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;</code></dd>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>sourceContext</code> - The context to emit elements to and for accessing locks.</dd>
<dt><span class="throwsLabel">抛出:</span></dt>
<dd><code>java.lang.Exception</code></dd>
</dl>
</li>
</ul>
<a name="cancel--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cancel</h4>
<pre>public&nbsp;void&nbsp;cancel()</pre>
<div class="block"><span class="descfrmTypeLabel">从接口复制的说明:&nbsp;<code><a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.html#cancel--">SourceFunction</a></code></span></div>
<div class="block">Cancels the source. Most sources will have a while loop inside the
 <a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.html#run-org.apache.flink.streaming.api.functions.source.SourceFunction.SourceContext-"><code>SourceFunction.run(SourceContext)</code></a> method. The implementation needs to ensure that the
 source will break out of that loop after this method is called.

 <p>A typical pattern is to have an <code>"volatile boolean isRunning"</code> flag that is set to
 <code>false</code> in this method. That flag is checked in the loop condition.

 <p>When a source is canceled, the executing thread will also be interrupted
 (via <code>Thread.interrupt()</code>). The interruption happens strictly after this
 method has been called, so any interruption handler can rely on the fact that
 this method has completed. It is good practice to make any flags altered by
 this method "volatile", in order to guarantee the visibility of the effects of
 this method to any interruption handler.</div>
<dl>
<dt><span class="overrideSpecifyLabel">指定者:</span></dt>
<dd><code><a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.html#cancel--">cancel</a></code>&nbsp;在接口中&nbsp;<code><a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.html" title="org.apache.flink.streaming.api.functions.source中的接口">SourceFunction</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;</code></dd>
</dl>
</li>
</ul>
<a name="close--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>close</h4>
<pre>public&nbsp;void&nbsp;close()
           throws java.lang.Exception</pre>
<div class="block"><span class="descfrmTypeLabel">从接口复制的说明:&nbsp;<code><a href="../../../../../../org/apache/flink/api/common/functions/RichFunction.html#close--">RichFunction</a></code></span></div>
<div class="block">Tear-down method for the user code. It is called after the last call to the main working methods
 (e.g. <i>map</i> or <i>join</i>). For functions that  are part of an iteration, this method will
 be invoked after each iteration superstep.
 <p>
 This method can be used for clean up work.</div>
<dl>
<dt><span class="overrideSpecifyLabel">指定者:</span></dt>
<dd><code><a href="../../../../../../org/apache/flink/api/common/functions/RichFunction.html#close--">close</a></code>&nbsp;在接口中&nbsp;<code><a href="../../../../../../org/apache/flink/api/common/functions/RichFunction.html" title="org.apache.flink.api.common.functions中的接口">RichFunction</a></code></dd>
<dt><span class="overrideSpecifyLabel">覆盖:</span></dt>
<dd><code><a href="../../../../../../org/apache/flink/api/common/functions/AbstractRichFunction.html#close--">close</a></code>&nbsp;在类中&nbsp;<code><a href="../../../../../../org/apache/flink/api/common/functions/AbstractRichFunction.html" title="org.apache.flink.api.common.functions中的类">AbstractRichFunction</a></code></dd>
<dt><span class="throwsLabel">抛出:</span></dt>
<dd><code>java.lang.Exception</code> - Implementations may forward exceptions, which are caught by the runtime. When the
                   runtime catches an exception, it aborts the task and lets the fail-over logic
                   decide whether to retry the task execution.</dd>
</dl>
</li>
</ul>
<a name="initializeState-org.apache.flink.runtime.state.FunctionInitializationContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initializeState</h4>
<pre>public final&nbsp;void&nbsp;initializeState(<a href="../../../../../../org/apache/flink/runtime/state/FunctionInitializationContext.html" title="org.apache.flink.runtime.state中的接口">FunctionInitializationContext</a>&nbsp;context)
                           throws java.lang.Exception</pre>
<div class="block"><span class="descfrmTypeLabel">从接口复制的说明:&nbsp;<code><a href="../../../../../../org/apache/flink/streaming/api/checkpoint/CheckpointedFunction.html#initializeState-org.apache.flink.runtime.state.FunctionInitializationContext-">CheckpointedFunction</a></code></span></div>
<div class="block">This method is called when the parallel function instance is created during distributed
 execution. Functions typically set up their state storing data structures in this method.</div>
<dl>
<dt><span class="overrideSpecifyLabel">指定者:</span></dt>
<dd><code><a href="../../../../../../org/apache/flink/streaming/api/checkpoint/CheckpointedFunction.html#initializeState-org.apache.flink.runtime.state.FunctionInitializationContext-">initializeState</a></code>&nbsp;在接口中&nbsp;<code><a href="../../../../../../org/apache/flink/streaming/api/checkpoint/CheckpointedFunction.html" title="org.apache.flink.streaming.api.checkpoint中的接口">CheckpointedFunction</a></code></dd>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>context</code> - the context for initializing the operator</dd>
<dt><span class="throwsLabel">抛出:</span></dt>
<dd><code>java.lang.Exception</code></dd>
</dl>
</li>
</ul>
<a name="snapshotState-org.apache.flink.runtime.state.FunctionSnapshotContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>snapshotState</h4>
<pre>public final&nbsp;void&nbsp;snapshotState(<a href="../../../../../../org/apache/flink/runtime/state/FunctionSnapshotContext.html" title="org.apache.flink.runtime.state中的接口">FunctionSnapshotContext</a>&nbsp;context)
                         throws java.lang.Exception</pre>
<div class="block"><span class="descfrmTypeLabel">从接口复制的说明:&nbsp;<code><a href="../../../../../../org/apache/flink/streaming/api/checkpoint/CheckpointedFunction.html#snapshotState-org.apache.flink.runtime.state.FunctionSnapshotContext-">CheckpointedFunction</a></code></span></div>
<div class="block">This method is called when a snapshot for a checkpoint is requested. This acts as a hook to the function to
 ensure that all state is exposed by means previously offered through <a href="../../../../../../org/apache/flink/runtime/state/FunctionInitializationContext.html" title="org.apache.flink.runtime.state中的接口"><code>FunctionInitializationContext</code></a> when
 the Function was initialized, or offered now by <a href="../../../../../../org/apache/flink/runtime/state/FunctionSnapshotContext.html" title="org.apache.flink.runtime.state中的接口"><code>FunctionSnapshotContext</code></a> itself.</div>
<dl>
<dt><span class="overrideSpecifyLabel">指定者:</span></dt>
<dd><code><a href="../../../../../../org/apache/flink/streaming/api/checkpoint/CheckpointedFunction.html#snapshotState-org.apache.flink.runtime.state.FunctionSnapshotContext-">snapshotState</a></code>&nbsp;在接口中&nbsp;<code><a href="../../../../../../org/apache/flink/streaming/api/checkpoint/CheckpointedFunction.html" title="org.apache.flink.streaming.api.checkpoint中的接口">CheckpointedFunction</a></code></dd>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>context</code> - the context for drawing a snapshot of the operator</dd>
<dt><span class="throwsLabel">抛出:</span></dt>
<dd><code>java.lang.Exception</code></dd>
</dl>
</li>
</ul>
<a name="notifyCheckpointComplete-long-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>notifyCheckpointComplete</h4>
<pre>public final&nbsp;void&nbsp;notifyCheckpointComplete(long&nbsp;checkpointId)
                                    throws java.lang.Exception</pre>
<div class="block"><span class="descfrmTypeLabel">从接口复制的说明:&nbsp;<code><a href="../../../../../../org/apache/flink/runtime/state/CheckpointListener.html#notifyCheckpointComplete-long-">CheckpointListener</a></code></span></div>
<div class="block">This method is called as a notification once a distributed checkpoint has been completed.
 
 Note that any exception during this method will not cause the checkpoint to
 fail any more.</div>
<dl>
<dt><span class="overrideSpecifyLabel">指定者:</span></dt>
<dd><code><a href="../../../../../../org/apache/flink/runtime/state/CheckpointListener.html#notifyCheckpointComplete-long-">notifyCheckpointComplete</a></code>&nbsp;在接口中&nbsp;<code><a href="../../../../../../org/apache/flink/runtime/state/CheckpointListener.html" title="org.apache.flink.runtime.state中的接口">CheckpointListener</a></code></dd>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>checkpointId</code> - The ID of the checkpoint that has been completed.</dd>
<dt><span class="throwsLabel">抛出:</span></dt>
<dd><code>java.lang.Exception</code></dd>
</dl>
</li>
</ul>
<a name="createFetcher-org.apache.flink.streaming.api.functions.source.SourceFunction.SourceContext-java.util.Map-org.apache.flink.util.SerializedValue-org.apache.flink.util.SerializedValue-org.apache.flink.streaming.api.operators.StreamingRuntimeContext-org.apache.flink.streaming.connectors.kafka.config.OffsetCommitMode-org.apache.flink.metrics.MetricGroup-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createFetcher</h4>
<pre>protected abstract&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/AbstractFetcher.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">AbstractFetcher</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>,?&gt;&nbsp;createFetcher(<a href="../../../../../../org/apache/flink/streaming/api/functions/source/SourceFunction.SourceContext.html" title="org.apache.flink.streaming.api.functions.source中的接口">SourceFunction.SourceContext</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;sourceContext,
                                                      java.util.Map&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt;&nbsp;subscribedPartitionsToStartOffsets,
                                                      <a href="../../../../../../org/apache/flink/util/SerializedValue.html" title="org.apache.flink.util中的类">SerializedValue</a>&lt;<a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPeriodicWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口">AssignerWithPeriodicWatermarks</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&gt;&nbsp;watermarksPeriodic,
                                                      <a href="../../../../../../org/apache/flink/util/SerializedValue.html" title="org.apache.flink.util中的类">SerializedValue</a>&lt;<a href="../../../../../../org/apache/flink/streaming/api/functions/AssignerWithPunctuatedWatermarks.html" title="org.apache.flink.streaming.api.functions中的接口">AssignerWithPunctuatedWatermarks</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&gt;&nbsp;watermarksPunctuated,
                                                      <a href="../../../../../../org/apache/flink/streaming/api/operators/StreamingRuntimeContext.html" title="org.apache.flink.streaming.api.operators中的类">StreamingRuntimeContext</a>&nbsp;runtimeContext,
                                                      <a href="../../../../../../org/apache/flink/streaming/connectors/kafka/config/OffsetCommitMode.html" title="org.apache.flink.streaming.connectors.kafka.config中的枚举">OffsetCommitMode</a>&nbsp;offsetCommitMode,
                                                      <a href="../../../../../../org/apache/flink/metrics/MetricGroup.html" title="org.apache.flink.metrics中的接口">MetricGroup</a>&nbsp;kafkaMetricGroup,
                                                      boolean&nbsp;useMetrics)
                                               throws java.lang.Exception</pre>
<div class="block">Creates the fetcher that connect to the Kafka brokers, pulls data, deserialized the
 data, and emits it into the data streams.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>sourceContext</code> - The source context to emit data to.</dd>
<dd><code>subscribedPartitionsToStartOffsets</code> - The set of partitions that this subtask should handle, with their start offsets.</dd>
<dd><code>watermarksPeriodic</code> - Optional, a serialized timestamp extractor / periodic watermark generator.</dd>
<dd><code>watermarksPunctuated</code> - Optional, a serialized timestamp extractor / punctuated watermark generator.</dd>
<dd><code>runtimeContext</code> - The task's runtime context.</dd>
<dt><span class="returnLabel">返回:</span></dt>
<dd>The instantiated fetcher</dd>
<dt><span class="throwsLabel">抛出:</span></dt>
<dd><code>java.lang.Exception</code> - The method should forward exceptions</dd>
</dl>
</li>
</ul>
<a name="createPartitionDiscoverer-org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicsDescriptor-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createPartitionDiscoverer</h4>
<pre>protected abstract&nbsp;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/AbstractPartitionDiscoverer.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">AbstractPartitionDiscoverer</a>&nbsp;createPartitionDiscoverer(<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicsDescriptor.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicsDescriptor</a>&nbsp;topicsDescriptor,
                                                                         int&nbsp;indexOfThisSubtask,
                                                                         int&nbsp;numParallelSubtasks)</pre>
<div class="block">Creates the partition discoverer that is used to find new partitions for this subtask.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>topicsDescriptor</code> - Descriptor that describes whether we are discovering partitions for fixed topics or a topic pattern.</dd>
<dd><code>indexOfThisSubtask</code> - The index of this consumer subtask.</dd>
<dd><code>numParallelSubtasks</code> - The total number of parallel consumer subtasks.</dd>
<dt><span class="returnLabel">返回:</span></dt>
<dd>The instantiated partition discoverer</dd>
</dl>
</li>
</ul>
<a name="getIsAutoCommitEnabled--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getIsAutoCommitEnabled</h4>
<pre>protected abstract&nbsp;boolean&nbsp;getIsAutoCommitEnabled()</pre>
</li>
</ul>
<a name="getProducedType--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getProducedType</h4>
<pre>public&nbsp;<a href="../../../../../../org/apache/flink/api/common/typeinfo/TypeInformation.html" title="org.apache.flink.api.common.typeinfo中的类">TypeInformation</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;&nbsp;getProducedType()</pre>
<div class="block"><span class="descfrmTypeLabel">从接口复制的说明:&nbsp;<code><a href="../../../../../../org/apache/flink/api/java/typeutils/ResultTypeQueryable.html#getProducedType--">ResultTypeQueryable</a></code></span></div>
<div class="block">Gets the data type (as a <a href="../../../../../../org/apache/flink/api/common/typeinfo/TypeInformation.html" title="org.apache.flink.api.common.typeinfo中的类"><code>TypeInformation</code></a>) produced by this function or input format.</div>
<dl>
<dt><span class="overrideSpecifyLabel">指定者:</span></dt>
<dd><code><a href="../../../../../../org/apache/flink/api/java/typeutils/ResultTypeQueryable.html#getProducedType--">getProducedType</a></code>&nbsp;在接口中&nbsp;<code><a href="../../../../../../org/apache/flink/api/java/typeutils/ResultTypeQueryable.html" title="org.apache.flink.api.java.typeutils中的接口">ResultTypeQueryable</a>&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" title="FlinkKafkaConsumerBase中的类型参数">T</a>&gt;</code></dd>
<dt><span class="returnLabel">返回:</span></dt>
<dd>The data type produced by this function or input format.</dd>
</dl>
</li>
</ul>
<a name="getSubscribedPartitionsToStartOffsets--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getSubscribedPartitionsToStartOffsets</h4>
<pre><a href="../../../../../../org/apache/flink/annotation/VisibleForTesting.html" title="org.apache.flink.annotation中的注释">@VisibleForTesting</a>
java.util.Map&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt;&nbsp;getSubscribedPartitionsToStartOffsets()</pre>
</li>
</ul>
<a name="getRestoredState--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getRestoredState</h4>
<pre><a href="../../../../../../org/apache/flink/annotation/VisibleForTesting.html" title="org.apache.flink.annotation中的注释">@VisibleForTesting</a>
java.util.TreeMap&lt;<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/internals/KafkaTopicPartition.html" title="org.apache.flink.streaming.connectors.kafka.internals中的类">KafkaTopicPartition</a>,java.lang.Long&gt;&nbsp;getRestoredState()</pre>
</li>
</ul>
<a name="getOffsetCommitMode--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getOffsetCommitMode</h4>
<pre><a href="../../../../../../org/apache/flink/annotation/VisibleForTesting.html" title="org.apache.flink.annotation中的注释">@VisibleForTesting</a>
<a href="../../../../../../org/apache/flink/streaming/connectors/kafka/config/OffsetCommitMode.html" title="org.apache.flink.streaming.connectors.kafka.config中的枚举">OffsetCommitMode</a>&nbsp;getOffsetCommitMode()</pre>
</li>
</ul>
<a name="getPendingOffsetsToCommit--">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>getPendingOffsetsToCommit</h4>
<pre><a href="../../../../../../org/apache/flink/annotation/VisibleForTesting.html" title="org.apache.flink.annotation中的注释">@VisibleForTesting</a>
org.apache.commons.collections.map.LinkedMap&nbsp;getPendingOffsetsToCommit()</pre>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../../../../index-files/index-1.html">索引</a></li>
<li><a href="../../../../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer09.html" title="org.apache.flink.streaming.connectors.kafka中的类"><span class="typeNameLink">上一个类</span></a></li>
<li><a href="../../../../../../org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducer.html" title="org.apache.flink.streaming.connectors.kafka中的类"><span class="typeNameLink">下一个类</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../../index.html?org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.html" target="_top">框架</a></li>
<li><a href="FlinkKafkaConsumerBase.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li>嵌套&nbsp;|&nbsp;</li>
<li><a href="#field.summary">字段</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li><a href="#field.detail">字段</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
