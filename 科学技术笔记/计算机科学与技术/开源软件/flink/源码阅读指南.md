# 源码阅读指南

## 找出main函数的类

```
find . -name *.java | xargs grep -i -E ' main\(' | grep -v "\*" | grep -v "//" | grep -v new

find . -name *.scala | xargs grep -i -E ' main\(' | grep -v "\*" | grep -v "//" | grep -v new
```

## 通过shell脚本找到启动参数

```

/Library/Java/JavaVirtualMachines/jdk1.8.0_144.jdk/Contents/Home/bin/java -Xms1024m -Xmx1024m -Dlog.file=/Users/zlq/Projects/oss/BigData/flink/flink-dist/target/flink-1.4.2-bin/flink-1.4.2/log/flink-zlq-jobmanager-1-zlqMacBookPro2015MidA1398.log -Dlog4j.configuration=file:/Users/zlq/Projects/oss/BigData/flink/flink-dist/target/flink-1.4.2-bin/flink-1.4.2/conf/log4j.properties -Dlogback.configurationFile=file:/Users/zlq/Projects/oss/BigData/flink/flink-dist/target/flink-1.4.2-bin/flink-1.4.2/conf/logback.xml -classpath :/Users/zlq/Projects/oss/BigData/flink/flink-dist/target/flink-1.4.2-bin/flink-1.4.2/lib/flink-dist_2.11-1.4.2.jar:/Users/zlq/Projects/oss/BigData/flink/flink-dist/target/flink-1.4.2-bin/flink-1.4.2/lib/flink-python_2.11-1.4.2.jar:/Users/zlq/Projects/oss/BigData/flink/flink-dist/target/flink-1.4.2-bin/flink-1.4.2/lib/flink-shaded-hadoop2-uber-1.4.2.jar:/Users/zlq/Projects/oss/BigData/flink/flink-dist/target/flink-1.4.2-bin/flink-1.4.2/lib/log4j-1.2.17.jar:/Users/zlq/Projects/oss/BigData/flink/flink-dist/target/flink-1.4.2-bin/flink-1.4.2/lib/slf4j-log4j12-1.7.7.jar::: org.apache.flink.runtime.jobmanager.JobManager --configDir /Users/zlq/Projects/oss/BigData/flink/flink-dist/target/flink-1.4.2-bin/flink-1.4.2/conf --executionMode cluster --host localhost --webui-port 8081




-Xms1024m -Xmx1024m -Dlog.file=/Users/zlq/Projects/oss/BigData/flink/logs/flink-zlq-jobmanager-1-zlqMacBookPro2015MidA1398.log -Dlog4j.configuration=file:/Users/zlq/Projects/oss/BigData/flink/flink-dist/src/main/flink-bin/conf/log4j.properties -Dlogback.configurationFile=file:/Users/zlq/Projects/oss/BigData/flink/flink-dist/src/main/flink-bin/conf/logback.xml

-classpath :/Users/zlq/Projects/oss/BigData/flink/flink-dist/target/flink-1.4.2-bin/flink-1.4.2/lib/flink-dist_2.11-1.4.2.jar:/Users/zlq/Projects/oss/BigData/flink/flink-dist/target/flink-1.4.2-bin/flink-1.4.2/lib/flink-python_2.11-1.4.2.jar:/Users/zlq/Projects/oss/BigData/flink/flink-dist/target/flink-1.4.2-bin/flink-1.4.2/lib/flink-shaded-hadoop2-uber-1.4.2.jar:/Users/zlq/Projects/oss/BigData/flink/flink-dist/target/flink-1.4.2-bin/flink-1.4.2/lib/log4j-1.2.17.jar:/Users/zlq/Projects/oss/BigData/flink/flink-dist/target/flink-1.4.2-bin/flink-1.4.2/lib/slf4j-log4j12-1.7.7.jar:::


org.apache.flink.runtime.jobmanager.JobManager

--configDir /Users/zlq/Projects/oss/BigData/flink/flink-dist/src/main/resources --executionMode cluster --host localhost --webui-port 8081
```

bin/jobmanager.sh start cluster

```
/tmp/flink-zlq-jobmanager.pid
flink-zlq-taskmanager.pid
```


bin/jobmanager.sh stop ''

bin/flink-daemon.sh stop jobmanager


taskmanager.sh stop ''


## 代码内容提取工具

```
if [ $# -eq 2 ];then
	echo 'usage: extractClassFieldsToCsv [file_name]'
	exit
fi

file=$1
prefix=`echo $file | cut -f 1 -d '.'`
type=`echo $file | cut -f 2 -d '.'`
suffix=`echo $file | cut -f 3 -d '.'`

cat $file | grep -v -E ' static ' | sed '/^[ \t*]*\//d;/^[ \t*]*@/d;/^[ \t]*\*/d;/^$/d' | sed 's/[ ]*extends[ ]*/extends/g;s/[ ]*super[ ]*/super/g;s/transient//;s/volatile//g;s/,[ ]*/,/g;s/private//g;s/protected//g;s/public//g;s/final//g;s/;//g' | awk 'BEGIN{OFS="\t"}{print $1,$2}' > $prefix"."$type".csv."$suffix

[[ ! -s "$prefix"."$type".csv."$suffix" ]] && rm $prefix"."$type".csv."$suffix

cat $file | grep -E ' static ' | sed '/^[ \t*]*\//d;/^[ \t*]*@/d;/^[ \t]*\*/d;/^$/d' | sed 's/[ ]*extends[ ]*/extends/g;s/[ ]*super[ ]*/super/g;s/transient//;s/volatile//g;s/,[ ]*/,/g;s/private//g;s/protected//g;s/public//g;s/final//g;s/static//g;s/;//g' | awk 'BEGIN{OFS="\t"}{print $1,$2}' > $prefix"."$type".static.csv."$suffix

[[ ! -s "$prefix"."$type".static.csv."$suffix" ]] && rm $prefix"."$type".static.csv."$suffix
```


```
ls *.fields.txt | awk '{print "extractClassFieldsToCsv "$1}' > bash.sh
```
