\documentclass{article}
\usepackage{geometry}
\geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }
\usepackage{fontspec}

\usepackage{xunicode}

\usepackage{xltxtra}
\usepackage{indentfirst}

\usepackage{biblatex}
\addbibresource{fst.bib}

\usepackage{listings}

\usepackage{tikz}
\usetikzlibrary{shapes.geometric}

\setromanfont{SimSun}

\XeTeXlinebreaklocale “zh”
\XeTeXlinebreakskip = 0pt plus 1pt minus 0.1pt

\newcommand\Helvetica{\fontspec {Helvetica}}

\begin{document}
\abstract{许多任务涉及到预测大量变量的值，这些变量互相有依赖，这些变量且依赖其它观测到的变量。结构化的预测方法本质上是分类模型和图模型的结合体。结构化的预测方法结合了图模型的紧凑地对多变量数据建模的能力和分类方法使用大量输入特征集执行预测的能力。这个调查描述了随机条件场（conditional random fields），一种流行的用于结构化预测的概率方法。CRFs已经在很多领域有广泛的应用，包括自然语言处理，计算机视觉和生物信息学。我们描述CRF的推断和参数估计方法，包括实现大规模CRFs的事件问题。我们不假设先前的图建模知识，所以这个调查适用于广泛领域的实践者。}

\section{导论}

\paragraph{}
很多应用的基础就是预测相互依赖的的多个变量的能力。这些应用，如一个图片区域分类[49,61,69]，在一个Go游戏中估计分数[130]，DNA的分段[7]，子软语言文本的句法解析[144]。在这些应用中，我们希望在给定一个观测到的特征向量x时，预测一个输出向量y={y0,y1,...,yT}，这个向量的元素为随机变量。一个来自自然语言处理的相对简单的例子是（part-of-speech tagging），在这里，每一个变量ys是在位置s的单词的part-of-speech tag，输入x分成特征向量{x0,x1,...,xT}。每一个xs包含在位置s的单词的不同信息，如身份、正交特征如前缀和后缀、领域特定的词典成员关系和语义数据库如WordNet的信息。
\paragraph{}
特别是如果我们的目标是最大化被正确分类的标签ys的数量，这个多变量预测问题的一个方法是学习出一个独立的每位置分类器，对每一个s，映射x->ys。然而，困难是输出变量有复杂的依赖。例如，在英语中，形容词通常不跟随名词，在计算机视觉中，一个图像的临近区域有相似的标签。另一个困难是输出变量可能代表一个复杂的结构如解析树，在这里，在树的高点临近处的语法规则选择对余下的树有大的影响。
\paragraph{}
一个表示输出变量互相依赖的自然方式由图模型提供。图模型--包含分化的模型族如贝叶斯网络，神经网络、因子图，马尔科夫随机场，Ising模型，代表

\end{document}



















